{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/CaliforniaHousing/cal_housing.data\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1     2       3       4       5       6       7         8\n",
       "0 -122.23  37.88  41.0   880.0   129.0   322.0   126.0  8.3252  452600.0\n",
       "1 -122.22  37.86  21.0  7099.0  1106.0  2401.0  1138.0  8.3014  358500.0\n",
       "2 -122.24  37.85  52.0  1467.0   190.0   496.0   177.0  7.2574  352100.0\n",
       "3 -122.25  37.85  52.0  1274.0   235.0   558.0   219.0  5.6431  341300.0\n",
       "4 -122.25  37.85  52.0  1627.0   280.0   565.0   259.0  3.8462  342200.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1].values\n",
    "y = np.log(df.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   8.3252    ,   41.        ,    6.98412698,    1.02380952,\n",
       "        322.        ,    2.55555556,   37.88      , -122.23      ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "scl = StandardScaler()\n",
    "X_train_scl = scl.fit_transform(X_train)\n",
    "X_test_scl = scl.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement a custom training loop:\n",
    "\n",
    "- A way to generate batches from where to sample.\n",
    "- For every epoch:\n",
    " - for every step in an epoch:\n",
    "     - do a gradient update (update params of our network)\n",
    " - New estimate of loss function\n",
    " - Print out the metric value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(X, y, batch_size=32):\n",
    "    idxs = np.random.randint(0, X.shape[0], size=batch_size)\n",
    "    return X[idxs], y[idxs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.abs(y_true-y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 32\n",
    "steps_per_epoch = X_train.shape[0]//batch_size # // means integer division\n",
    "loss_fn = tf.keras.losses.mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_floatx('float64') # Remove the warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(30, activation='relu', input_shape=X_train.shape[1:]), \n",
    "    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(learning_rate=3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a validation set\n",
    "X_train_scl, X_val_scl, y_train, y_val = train_test_split(X_train_scl, y_train, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 loss function (train set) 1.5412447442065607 loss function (val set) 2.000838747133028\n",
      "Epoch:  1 loss function (train set) 1.4615463869813143 loss function (val set) 1.7858828097282864\n",
      "Epoch:  2 loss function (train set) 1.4286088692106642 loss function (val set) 1.686841785638539\n",
      "Epoch:  3 loss function (train set) 1.4070622714992398 loss function (val set) 1.6066884683415603\n",
      "Epoch:  4 loss function (train set) 1.3848199842100393 loss function (val set) 1.5576846423743742\n",
      "Epoch:  5 loss function (train set) 1.375694851750518 loss function (val set) 1.5218410374022413\n",
      "Epoch:  6 loss function (train set) 1.370753842635492 loss function (val set) 1.4801169898063036\n",
      "Epoch:  7 loss function (train set) 1.3640744156365787 loss function (val set) 1.4556224919823384\n",
      "Epoch:  8 loss function (train set) 1.3583666965187715 loss function (val set) 1.4430871888824424\n",
      "Epoch:  9 loss function (train set) 1.3550475394305996 loss function (val set) 1.4255395620778724\n",
      "Epoch:  10 loss function (train set) 1.3534011764941487 loss function (val set) 1.4098788552247128\n",
      "Epoch:  11 loss function (train set) 1.3504878682655779 loss function (val set) 1.4021366140438696\n",
      "Epoch:  12 loss function (train set) 1.3491656681200266 loss function (val set) 1.4003719446699805\n",
      "Epoch:  13 loss function (train set) 1.3474665222329805 loss function (val set) 1.3898362034732386\n",
      "Epoch:  14 loss function (train set) 1.3491722503055823 loss function (val set) 1.382935683926274\n",
      "Epoch:  15 loss function (train set) 1.345793216965196 loss function (val set) 1.382083450749537\n",
      "Epoch:  16 loss function (train set) 1.3453806422306696 loss function (val set) 1.3743186725081784\n",
      "Epoch:  17 loss function (train set) 1.3441199336401368 loss function (val set) 1.3711510548332466\n",
      "Epoch:  18 loss function (train set) 1.347208473225667 loss function (val set) 1.3760324178854415\n",
      "Epoch:  19 loss function (train set) 1.3452817275305746 loss function (val set) 1.3645780092260122\n",
      "Epoch:  20 loss function (train set) 1.342409604380147 loss function (val set) 1.3618664270416125\n",
      "Epoch:  21 loss function (train set) 1.3426019054204374 loss function (val set) 1.3617074873655797\n",
      "Epoch:  22 loss function (train set) 1.3418851889612233 loss function (val set) 1.35737887842698\n",
      "Epoch:  23 loss function (train set) 1.341800035487169 loss function (val set) 1.3561526814398694\n",
      "Epoch:  24 loss function (train set) 1.3416496191574347 loss function (val set) 1.3543785477304586\n",
      "Epoch:  25 loss function (train set) 1.3410054138867455 loss function (val set) 1.354419170564809\n",
      "Epoch:  26 loss function (train set) 1.3413788294611617 loss function (val set) 1.352483259417882\n",
      "Epoch:  27 loss function (train set) 1.341470373460896 loss function (val set) 1.3514159311973781\n",
      "Epoch:  28 loss function (train set) 1.3411987329475998 loss function (val set) 1.352960162744566\n",
      "Epoch:  29 loss function (train set) 1.3409582257257022 loss function (val set) 1.3495015656361486\n",
      "Epoch:  30 loss function (train set) 1.3402981609699778 loss function (val set) 1.349033758429391\n",
      "Epoch:  31 loss function (train set) 1.3402624957562321 loss function (val set) 1.3481685535985204\n",
      "Epoch:  32 loss function (train set) 1.3401830950729658 loss function (val set) 1.3479005094334195\n",
      "Epoch:  33 loss function (train set) 1.3412752555484917 loss function (val set) 1.3492827043374727\n",
      "Epoch:  34 loss function (train set) 1.3400338135818177 loss function (val set) 1.3460094793774275\n",
      "Epoch:  35 loss function (train set) 1.3397314974070582 loss function (val set) 1.3453716585711273\n",
      "Epoch:  36 loss function (train set) 1.340243097046061 loss function (val set) 1.3462511203293417\n",
      "Epoch:  37 loss function (train set) 1.3395101186741696 loss function (val set) 1.3442025778257725\n",
      "Epoch:  38 loss function (train set) 1.339515694793206 loss function (val set) 1.3443724490080533\n",
      "Epoch:  39 loss function (train set) 1.3396195895077945 loss function (val set) 1.3428378901622429\n",
      "Epoch:  40 loss function (train set) 1.339547581666825 loss function (val set) 1.3425675387643023\n",
      "Epoch:  41 loss function (train set) 1.3401765790770443 loss function (val set) 1.3429433734387608\n",
      "Epoch:  42 loss function (train set) 1.339626257017949 loss function (val set) 1.3436419445415384\n",
      "Epoch:  43 loss function (train set) 1.3391096081613743 loss function (val set) 1.3420283485521662\n",
      "Epoch:  44 loss function (train set) 1.3405308184193707 loss function (val set) 1.3446339454636405\n",
      "Epoch:  45 loss function (train set) 1.33915623121832 loss function (val set) 1.3413864652984413\n",
      "Epoch:  46 loss function (train set) 1.3395452150648377 loss function (val set) 1.343066427091563\n",
      "Epoch:  47 loss function (train set) 1.3395146012282924 loss function (val set) 1.3422848903051492\n",
      "Epoch:  48 loss function (train set) 1.339152709213733 loss function (val set) 1.3405091124287007\n",
      "Epoch:  49 loss function (train set) 1.338657657423195 loss function (val set) 1.3404681190500147\n",
      "Epoch:  50 loss function (train set) 1.3389616764771648 loss function (val set) 1.340468100070601\n",
      "Epoch:  51 loss function (train set) 1.340120673280442 loss function (val set) 1.3425765026194172\n",
      "Epoch:  52 loss function (train set) 1.338690514013951 loss function (val set) 1.3405692328866057\n",
      "Epoch:  53 loss function (train set) 1.3390223727702077 loss function (val set) 1.3411805823878455\n",
      "Epoch:  54 loss function (train set) 1.3418402673611842 loss function (val set) 1.3422488316332521\n",
      "Epoch:  55 loss function (train set) 1.338602025891752 loss function (val set) 1.339796890710615\n",
      "Epoch:  56 loss function (train set) 1.3385431182242842 loss function (val set) 1.339122474228641\n",
      "Epoch:  57 loss function (train set) 1.3399685394704433 loss function (val set) 1.3397284969152392\n",
      "Epoch:  58 loss function (train set) 1.338522213572339 loss function (val set) 1.3392589074708885\n",
      "Epoch:  59 loss function (train set) 1.339852166619435 loss function (val set) 1.341079571876415\n",
      "Epoch:  60 loss function (train set) 1.3402453042608724 loss function (val set) 1.341480870125504\n",
      "Epoch:  61 loss function (train set) 1.338231653597454 loss function (val set) 1.3382418619795529\n",
      "Epoch:  62 loss function (train set) 1.338286714812332 loss function (val set) 1.3381217232401177\n",
      "Epoch:  63 loss function (train set) 1.340197152615498 loss function (val set) 1.340996168475124\n",
      "Epoch:  64 loss function (train set) 1.3424417359573062 loss function (val set) 1.3414346530122256\n",
      "Epoch:  65 loss function (train set) 1.3381592528350235 loss function (val set) 1.33802431811088\n",
      "Epoch:  66 loss function (train set) 1.3381097142150815 loss function (val set) 1.3378337651884153\n",
      "Epoch:  67 loss function (train set) 1.3380919116780994 loss function (val set) 1.337828944588775\n",
      "Epoch:  68 loss function (train set) 1.3388547164180689 loss function (val set) 1.3382093149915837\n",
      "Epoch:  69 loss function (train set) 1.3384066219085133 loss function (val set) 1.3376532655202964\n",
      "Epoch:  70 loss function (train set) 1.3379983637882835 loss function (val set) 1.3372904414784892\n",
      "Epoch:  71 loss function (train set) 1.3382359748637231 loss function (val set) 1.3375680194939918\n",
      "Epoch:  72 loss function (train set) 1.3384929984175729 loss function (val set) 1.3379155588753904\n",
      "Epoch:  73 loss function (train set) 1.3380912551171074 loss function (val set) 1.3369429925538765\n",
      "Epoch:  74 loss function (train set) 1.338803467983683 loss function (val set) 1.3373223187604195\n",
      "Epoch:  75 loss function (train set) 1.3383219124436159 loss function (val set) 1.3376054284211178\n",
      "Epoch:  76 loss function (train set) 1.337916619131608 loss function (val set) 1.3368255642826146\n",
      "Epoch:  77 loss function (train set) 1.3378653428161484 loss function (val set) 1.3364951294943987\n",
      "Epoch:  78 loss function (train set) 1.3387084367653501 loss function (val set) 1.3367604275034308\n",
      "Epoch:  79 loss function (train set) 1.3384466410809184 loss function (val set) 1.336614286851742\n",
      "Epoch:  80 loss function (train set) 1.337812331871956 loss function (val set) 1.3363680219813565\n",
      "Epoch:  81 loss function (train set) 1.3378077597976024 loss function (val set) 1.3360902081494368\n",
      "Epoch:  82 loss function (train set) 1.337840898174407 loss function (val set) 1.336307334833809\n",
      "Epoch:  83 loss function (train set) 1.337805926800658 loss function (val set) 1.3360759014936783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  84 loss function (train set) 1.3377408289629384 loss function (val set) 1.3356372016980604\n",
      "Epoch:  85 loss function (train set) 1.3382098526627066 loss function (val set) 1.3363436693980943\n",
      "Epoch:  86 loss function (train set) 1.337841707192107 loss function (val set) 1.335388061949932\n",
      "Epoch:  87 loss function (train set) 1.3376696340972634 loss function (val set) 1.3352677866716196\n",
      "Epoch:  88 loss function (train set) 1.3382488833072876 loss function (val set) 1.335623102129067\n",
      "Epoch:  89 loss function (train set) 1.3380723253938973 loss function (val set) 1.3361457049979957\n",
      "Epoch:  90 loss function (train set) 1.3386806806168847 loss function (val set) 1.3365712604979472\n",
      "Epoch:  91 loss function (train set) 1.3379570006450465 loss function (val set) 1.3357212484990644\n",
      "Epoch:  92 loss function (train set) 1.3381439307931429 loss function (val set) 1.3358866883507523\n",
      "Epoch:  93 loss function (train set) 1.3375267398813981 loss function (val set) 1.3346656092591602\n",
      "Epoch:  94 loss function (train set) 1.337870826603123 loss function (val set) 1.3351345581861545\n",
      "Epoch:  95 loss function (train set) 1.337589485171233 loss function (val set) 1.3347350034068752\n",
      "Epoch:  96 loss function (train set) 1.3375095236096965 loss function (val set) 1.3346774506523251\n",
      "Epoch:  97 loss function (train set) 1.3377655068509557 loss function (val set) 1.3351423106655849\n",
      "Epoch:  98 loss function (train set) 1.3375245878317374 loss function (val set) 1.3345943382528809\n",
      "Epoch:  99 loss function (train set) 1.3375863927582607 loss function (val set) 1.334702500402006\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for step in range(steps_per_epoch):\n",
    "        # Get a batch with our sampler\n",
    "        X_batch, y_batch = random_batch(X_train_scl, y_train, batch_size)\n",
    "        X_batch = scl.fit_transform(X_batch)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch) # Model predictions on the batch\n",
    "            loss = tf.reduce_mean(loss_fn(y_batch, y_pred)) # Measure loss function on the preds of current batch\n",
    "            \n",
    "        grads = tape.gradient(loss, model.variables) # Calculate gradient of the loss function wrt model.variables\n",
    "        grads_and_vars = zip(grads, model.variables)\n",
    "        optimizer.apply_gradients(grads_and_vars) # Commit our calculated gradients. Model is modified in-place\n",
    "    \n",
    "    # Look at the loss function after an epoch is completed\n",
    "    y_pred = model(X_train_scl)\n",
    "    epoch_loss = tf.reduce_mean(loss_fn(y_train, y_pred))\n",
    "    \n",
    "    # Same for the validation set\n",
    "    y_pred = model(X_val_scl)\n",
    "    epoch_val_loss = tf.reduce_mean(loss_fn(y_val, y_pred))\n",
    "    print(\"Epoch: \", epoch, \"loss function (train set)\", epoch_loss.numpy(), \"loss function (val set)\", epoch_val_loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
